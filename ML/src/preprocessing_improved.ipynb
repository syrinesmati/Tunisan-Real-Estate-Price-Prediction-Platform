{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Improved Real Estate Price Prediction Preprocessing\n",
    "## Tunisian Real Estate Dataset\n",
    "\n",
    "**Key Improvements:**\n",
    "1. Separate pipelines for rent and sale transactions\n",
    "2. Better handling of high-cardinality features (region)\n",
    "3. Feature engineering (price per sqm, region aggregations)\n",
    "4. Proper treatment of ordinal features\n",
    "5. Rare category grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 9,744\n",
      "\n",
      "Transaction distribution:\n",
      "transaction\n",
      "rent    5636\n",
      "sale    4108\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rent: 5,636 (57.8%)\n",
      "Sale: 4,108 (42.2%)\n"
     ]
    }
   ],
   "source": [
    "# Update this path to your data location\n",
    "DATA_PATH = \"C:\\\\Users\\\\user\\\\OneDrive\\\\Bureau\\\\Data Mining Projecy\\\\Tunisan-Real-Estate-Price-Prediction-Platform\\\\ML\\\\data\\\\processed\\\\cleaned_real_estate.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"\\nTransaction distribution:\")\n",
    "print(df['transaction'].value_counts())\n",
    "print(f\"\\nRent: {len(df[df['transaction']=='rent']):,} ({len(df[df['transaction']=='rent'])/len(df)*100:.1f}%)\")\n",
    "print(f\"Sale: {len(df[df['transaction']=='sale']):,} ({len(df[df['transaction']=='sale'])/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_eng_header",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Creating new features that will help the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original regions: 267\n",
      "Grouped regions: 100\n",
      "Rare regions grouped: 168\n"
     ]
    }
   ],
   "source": [
    "# Feature 1: Price per square meter (will be dropped later, used for aggregations)\n",
    "df['price_per_sqm'] = df['price'] / df['surface']\n",
    "\n",
    "# Feature 2: Total rooms (rooms + bathrooms)\n",
    "df['total_rooms'] = df['rooms'] + df['bathrooms']\n",
    "\n",
    "# Feature 3: Surface category (small, medium, large)\n",
    "df['surface_category'] = pd.cut(df['surface'], \n",
    "                                  bins=[0, 80, 150, 300, 10000],\n",
    "                                  labels=['small', 'medium', 'large', 'very_large'])\n",
    "\n",
    "# Feature 4: Region frequency (how common is this region?)\n",
    "region_counts = df['region'].value_counts()\n",
    "df['region_frequency'] = df['region'].map(region_counts)\n",
    "\n",
    "# Feature 5: Group rare regions (< 20 occurrences) into 'other'\n",
    "df['region_grouped'] = df['region'].copy()\n",
    "rare_regions = region_counts[region_counts < 20].index\n",
    "df.loc[df['region'].isin(rare_regions), 'region_grouped'] = 'other_region'\n",
    "\n",
    "print(f\"Original regions: {df['region'].nunique()}\")\n",
    "print(f\"Grouped regions: {df['region_grouped'].nunique()}\")\n",
    "print(f\"Rare regions grouped: {len(rare_regions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "target_encoding_header",
   "metadata": {},
   "source": [
    "## 3. Target Encoding for High Cardinality Features\n",
    "\n",
    "For regions, we'll create mean-encoded features (average price by region):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "target_encoding_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_encoding(df, column, target, min_samples=10):\n",
    "    \"\"\"\n",
    "    Create target encoding with smoothing for rare categories.\n",
    "    Returns the mapping dictionary.\n",
    "    \"\"\"\n",
    "    # Calculate global mean\n",
    "    global_mean = df[target].mean()\n",
    "    \n",
    "    # Calculate aggregations per category\n",
    "    agg = df.groupby(column)[target].agg(['mean', 'count'])\n",
    "    \n",
    "    # Smooth the means (for categories with few samples, pull towards global mean)\n",
    "    smoothing = 1.0\n",
    "    agg['smoothed_mean'] = (\n",
    "        (agg['count'] * agg['mean'] + smoothing * global_mean) / \n",
    "        (agg['count'] + smoothing)\n",
    "    )\n",
    "    \n",
    "    return agg['smoothed_mean'].to_dict(), global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_header",
   "metadata": {},
   "source": [
    "## 4. Split Data by Transaction Type\n",
    "\n",
    "**Critical Step:** Separate rent and sale data for independent modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "split_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rent dataset: 5,636 records\n",
      "Sale dataset: 4,108 records\n"
     ]
    }
   ],
   "source": [
    "# Split by transaction type\n",
    "df_rent = df[df['transaction'] == 'rent'].copy()\n",
    "df_sale = df[df['transaction'] == 'sale'].copy()\n",
    "\n",
    "print(f\"Rent dataset: {len(df_rent):,} records\")\n",
    "print(f\"Sale dataset: {len(df_sale):,} records\")\n",
    "\n",
    "# Drop transaction column as it's no longer needed\n",
    "df_rent = df_rent.drop(columns=['transaction'])\n",
    "df_sale = df_sale.drop(columns=['transaction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "target_encoding_apply_header",
   "metadata": {},
   "source": [
    "## 5. Create Target Encodings (Separate for Rent and Sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "create_encodings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 9\n",
      "Categorical: ['property_type', 'city', 'surface_category']\n",
      "Numerical: ['surface', 'region_frequency']\n",
      "Ordinal: ['rooms', 'bathrooms', 'total_rooms']\n",
      "Target encoded: ['region_grouped']\n"
     ]
    }
   ],
   "source": [
    "# We'll create these encodings on the training set only (to avoid data leakage)\n",
    "# For now, we'll prepare the data structure\n",
    "\n",
    "TARGET = 'price'\n",
    "\n",
    "# Define feature groups\n",
    "CATEGORICAL_COLS = [\n",
    "    'property_type',\n",
    "    'city',\n",
    "    'surface_category'\n",
    "]\n",
    "\n",
    "NUMERICAL_COLS = [\n",
    "    'surface',\n",
    "    'region_frequency'\n",
    "]\n",
    "\n",
    "# Treat rooms and bathrooms as ordinal (order matters)\n",
    "ORDINAL_COLS = [\n",
    "    'rooms',\n",
    "    'bathrooms',\n",
    "    'total_rooms'\n",
    "]\n",
    "\n",
    "# High cardinality features for target encoding\n",
    "TARGET_ENCODE_COLS = [\n",
    "    'region_grouped'\n",
    "]\n",
    "\n",
    "ALL_FEATURES = CATEGORICAL_COLS + NUMERICAL_COLS + ORDINAL_COLS + TARGET_ENCODE_COLS\n",
    "\n",
    "print(f\"Total features: {len(ALL_FEATURES)}\")\n",
    "print(f\"Categorical: {CATEGORICAL_COLS}\")\n",
    "print(f\"Numerical: {NUMERICAL_COLS}\")\n",
    "print(f\"Ordinal: {ORDINAL_COLS}\")\n",
    "print(f\"Target encoded: {TARGET_ENCODE_COLS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_test_split_header",
   "metadata": {},
   "source": [
    "## 6. Train-Test Split (Separate for Each Transaction Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "train_test_split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT SPLIT:\n",
      "  Train: 4,508 samples\n",
      "  Test:  1,128 samples\n",
      "\n",
      "SALE SPLIT:\n",
      "  Train: 3,286 samples\n",
      "  Test:  822 samples\n"
     ]
    }
   ],
   "source": [
    "# RENT data split\n",
    "X_rent = df_rent[ALL_FEATURES]\n",
    "y_rent = df_rent[TARGET]\n",
    "\n",
    "X_rent_train, X_rent_test, y_rent_train, y_rent_test = train_test_split(\n",
    "    X_rent, y_rent,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"RENT SPLIT:\")\n",
    "print(f\"  Train: {len(X_rent_train):,} samples\")\n",
    "print(f\"  Test:  {len(X_rent_test):,} samples\")\n",
    "\n",
    "# SALE data split\n",
    "X_sale = df_sale[ALL_FEATURES]\n",
    "y_sale = df_sale[TARGET]\n",
    "\n",
    "X_sale_train, X_sale_test, y_sale_train, y_sale_test = train_test_split(\n",
    "    X_sale, y_sale,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nSALE SPLIT:\")\n",
    "print(f\"  Train: {len(X_sale_train):,} samples\")\n",
    "print(f\"  Test:  {len(X_sale_test):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "target_encoding_fit_header",
   "metadata": {},
   "source": [
    "## 7. Fit Target Encodings on Training Data Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fit_target_encodings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target encodings created successfully!\n",
      "\n",
      "Rent - example region encodings:\n",
      "  Ain Zaghouan Nord: 1617.42 TND\n",
      "  Ain Zaghouan Sud: 1154.46 TND\n",
      "  Ain Zaghouen: 1241.57 TND\n",
      "  Akouda: 1232.24 TND\n",
      "  Ariana: 950.28 TND\n",
      "\n",
      "Sale - example region encodings:\n",
      "  Ain Zaghouan Nord: 422716.83 TND\n",
      "  Ain Zaghouan Sud: 615920.98 TND\n",
      "  Ain Zaghouen: 297845.37 TND\n",
      "  Akouda: 455418.39 TND\n",
      "  Ariana: 583383.42 TND\n"
     ]
    }
   ],
   "source": [
    "# Create target encodings for RENT\n",
    "rent_region_encoding, rent_region_global = create_target_encoding(\n",
    "    pd.concat([X_rent_train, y_rent_train], axis=1),\n",
    "    'region_grouped',\n",
    "    'price'\n",
    ")\n",
    "\n",
    "# Create target encodings for SALE  \n",
    "sale_region_encoding, sale_region_global = create_target_encoding(\n",
    "    pd.concat([X_sale_train, y_sale_train], axis=1),\n",
    "    'region_grouped',\n",
    "    'price'\n",
    ")\n",
    "\n",
    "print(\"Target encodings created successfully!\")\n",
    "print(f\"\\nRent - example region encodings:\")\n",
    "for region, value in list(rent_region_encoding.items())[:5]:\n",
    "    print(f\"  {region}: {value:.2f} TND\")\n",
    "    \n",
    "print(f\"\\nSale - example region encodings:\")\n",
    "for region, value in list(sale_region_encoding.items())[:5]:\n",
    "    print(f\"  {region}: {value:.2f} TND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apply_target_encoding_header",
   "metadata": {},
   "source": [
    "## 8. Apply Target Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "apply_target_encodings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target encoding applied!\n",
      "\n",
      "Updated numerical columns: ['surface', 'region_frequency', 'region_encoded']\n"
     ]
    }
   ],
   "source": [
    "# Apply to RENT data\n",
    "X_rent_train['region_encoded'] = X_rent_train['region_grouped'].map(rent_region_encoding).fillna(rent_region_global)\n",
    "X_rent_test['region_encoded'] = X_rent_test['region_grouped'].map(rent_region_encoding).fillna(rent_region_global)\n",
    "\n",
    "# Apply to SALE data\n",
    "X_sale_train['region_encoded'] = X_sale_train['region_grouped'].map(sale_region_encoding).fillna(sale_region_global)\n",
    "X_sale_test['region_encoded'] = X_sale_test['region_grouped'].map(sale_region_encoding).fillna(sale_region_global)\n",
    "\n",
    "# Drop the original region column\n",
    "X_rent_train = X_rent_train.drop(columns=['region_grouped'])\n",
    "X_rent_test = X_rent_test.drop(columns=['region_grouped'])\n",
    "X_sale_train = X_sale_train.drop(columns=['region_grouped'])\n",
    "X_sale_test = X_sale_test.drop(columns=['region_grouped'])\n",
    "\n",
    "# Update feature lists\n",
    "NUMERICAL_COLS.append('region_encoded')\n",
    "print(\"Target encoding applied!\")\n",
    "print(f\"\\nUpdated numerical columns: {NUMERICAL_COLS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing_pipeline_header",
   "metadata": {},
   "source": [
    "## 9. Create Preprocessing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "create_preprocessors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipelines created!\n"
     ]
    }
   ],
   "source": [
    "# Create the same preprocessor for both rent and sale\n",
    "def create_preprocessor():\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                'categorical',\n",
    "                OneHotEncoder(handle_unknown='ignore', sparse_output=False),\n",
    "                CATEGORICAL_COLS\n",
    "            ),\n",
    "            (\n",
    "                'numerical',\n",
    "                StandardScaler(),\n",
    "                NUMERICAL_COLS\n",
    "            ),\n",
    "            (\n",
    "                'ordinal',\n",
    "                StandardScaler(),  # Or keep as-is, depending on your preference\n",
    "                ORDINAL_COLS\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "preprocessor_rent = create_preprocessor()\n",
    "preprocessor_sale = create_preprocessor()\n",
    "\n",
    "print(\"Preprocessing pipelines created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fit_transform_header",
   "metadata": {},
   "source": [
    "## 10. Fit and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fit_transform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT data preprocessed:\n",
      "  Train shape: (4508, 36)\n",
      "  Test shape:  (1128, 36)\n",
      "\n",
      "SALE data preprocessed:\n",
      "  Train shape: (3286, 37)\n",
      "  Test shape:  (822, 37)\n"
     ]
    }
   ],
   "source": [
    "# RENT preprocessing\n",
    "X_rent_train_prepared = preprocessor_rent.fit_transform(X_rent_train)\n",
    "X_rent_test_prepared = preprocessor_rent.transform(X_rent_test)\n",
    "\n",
    "print(\"RENT data preprocessed:\")\n",
    "print(f\"  Train shape: {X_rent_train_prepared.shape}\")\n",
    "print(f\"  Test shape:  {X_rent_test_prepared.shape}\")\n",
    "\n",
    "# SALE preprocessing\n",
    "X_sale_train_prepared = preprocessor_sale.fit_transform(X_sale_train)\n",
    "X_sale_test_prepared = preprocessor_sale.transform(X_sale_test)\n",
    "\n",
    "print(\"\\nSALE data preprocessed:\")\n",
    "print(f\"  Train shape: {X_sale_train_prepared.shape}\")\n",
    "print(f\"  Test shape:  {X_sale_test_prepared.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_header",
   "metadata": {},
   "source": [
    "## 11. Save Preprocessed Data and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "save_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All data and pipelines saved successfully!\n",
      "\n",
      "Output directory: C:\\Users\\user\\OneDrive\\Bureau\\Data Mining Projecy\\Tunisan-Real-Estate-Price-Prediction-Platform\\ML\n",
      "\n",
      "Files saved:\n",
      "  - Rent: X_train, X_test, y_train, y_test\n",
      "  - Sale: X_train, X_test, y_train, y_test\n",
      "  - Preprocessors: preprocessor_rent.joblib, preprocessor_sale.joblib\n",
      "  - Target encodings: target_encodings_rent.joblib, target_encodings_sale.joblib\n"
     ]
    }
   ],
   "source": [
    "# Create output directories\n",
    "OUTPUT_DIR = \"C:\\\\Users\\\\user\\\\OneDrive\\\\Bureau\\\\Data Mining Projecy\\\\Tunisan-Real-Estate-Price-Prediction-Platform\\\\ML\"\n",
    "os.makedirs(f\"{OUTPUT_DIR}/data/prepared/rent\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/data/prepared/sale\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/data/preprocessing\", exist_ok=True)\n",
    "\n",
    "# Save RENT data\n",
    "np.save(f\"{OUTPUT_DIR}/data/prepared/rent/X_train.npy\", X_rent_train_prepared)\n",
    "np.save(f\"{OUTPUT_DIR}/data/prepared/rent/X_test.npy\", X_rent_test_prepared)\n",
    "np.save(f\"{OUTPUT_DIR}/data/prepared/rent/y_train.npy\", y_rent_train.to_numpy())\n",
    "np.save(f\"{OUTPUT_DIR}/data/prepared/rent/y_test.npy\", y_rent_test.to_numpy())\n",
    "\n",
    "# Save SALE data\n",
    "np.save(f\"{OUTPUT_DIR}/data/prepared/sale/X_train.npy\", X_sale_train_prepared)\n",
    "np.save(f\"{OUTPUT_DIR}/data/prepared/sale/X_test.npy\", X_sale_test_prepared)\n",
    "np.save(f\"{OUTPUT_DIR}/data/prepared/sale/y_train.npy\", y_sale_train.to_numpy())\n",
    "np.save(f\"{OUTPUT_DIR}/data/prepared/sale/y_test.npy\", y_sale_test.to_numpy())\n",
    "\n",
    "# Save preprocessors\n",
    "joblib.dump(\n",
    "    preprocessor_rent,\n",
    "    f\"{OUTPUT_DIR}/data/preprocessing/preprocessor_rent.joblib\"\n",
    ")\n",
    "joblib.dump(\n",
    "    preprocessor_sale,\n",
    "    f\"{OUTPUT_DIR}/data/preprocessing/preprocessor_sale.joblib\"\n",
    ")\n",
    "\n",
    "# Save target encodings\n",
    "joblib.dump(\n",
    "    {'region_encoding': rent_region_encoding, 'region_global': rent_region_global},\n",
    "    f\"{OUTPUT_DIR}/data/preprocessing/target_encodings_rent.joblib\"\n",
    ")\n",
    "joblib.dump(\n",
    "    {'region_encoding': sale_region_encoding, 'region_global': sale_region_global},\n",
    "    f\"{OUTPUT_DIR}/data/preprocessing/target_encodings_sale.joblib\"\n",
    ")\n",
    "\n",
    "print(\"âœ… All data and pipelines saved successfully!\")\n",
    "print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"  - Rent: X_train, X_test, y_train, y_test\")\n",
    "print(\"  - Sale: X_train, X_test, y_train, y_test\")\n",
    "print(\"  - Preprocessors: preprocessor_rent.joblib, preprocessor_sale.joblib\")\n",
    "print(\"  - Target encodings: target_encodings_rent.joblib, target_encodings_sale.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "## 12. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREPROCESSING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š DATASET SIZES:\n",
      "  Rent Train:  4,508 samples x 36 features\n",
      "  Rent Test:   1,128 samples x 36 features\n",
      "  Sale Train:  3,286 samples x 37 features\n",
      "  Sale Test:   822 samples x 37 features\n",
      "\n",
      "ðŸ’° PRICE STATISTICS:\n",
      "  RENT:\n",
      "    Train mean: 1469.09 TND\n",
      "    Train std:  1401.08 TND\n",
      "    Test mean:  1458.82 TND\n",
      "    Test std:   1357.72 TND\n",
      "  SALE:\n",
      "    Train mean: 478367.84 TND\n",
      "    Train std:  396574.43 TND\n",
      "    Test mean:  488662.96 TND\n",
      "    Test std:   423537.30 TND\n",
      "\n",
      "ðŸ”§ FEATURE ENGINEERING:\n",
      "  Original features: 7\n",
      "  Engineered features added: 2\n",
      "  Total features before encoding: 9\n",
      "  Total features after encoding: 36\n",
      "\n",
      "âœ… Ready for model training!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET SIZES:\")\n",
    "print(f\"  Rent Train:  {X_rent_train_prepared.shape[0]:,} samples x {X_rent_train_prepared.shape[1]} features\")\n",
    "print(f\"  Rent Test:   {X_rent_test_prepared.shape[0]:,} samples x {X_rent_test_prepared.shape[1]} features\")\n",
    "print(f\"  Sale Train:  {X_sale_train_prepared.shape[0]:,} samples x {X_sale_train_prepared.shape[1]} features\")\n",
    "print(f\"  Sale Test:   {X_sale_test_prepared.shape[0]:,} samples x {X_sale_test_prepared.shape[1]} features\")\n",
    "\n",
    "print(\"\\nðŸ’° PRICE STATISTICS:\")\n",
    "print(\"  RENT:\")\n",
    "print(f\"    Train mean: {y_rent_train.mean():.2f} TND\")\n",
    "print(f\"    Train std:  {y_rent_train.std():.2f} TND\")\n",
    "print(f\"    Test mean:  {y_rent_test.mean():.2f} TND\")\n",
    "print(f\"    Test std:   {y_rent_test.std():.2f} TND\")\n",
    "print(\"  SALE:\")\n",
    "print(f\"    Train mean: {y_sale_train.mean():.2f} TND\")\n",
    "print(f\"    Train std:  {y_sale_train.std():.2f} TND\")\n",
    "print(f\"    Test mean:  {y_sale_test.mean():.2f} TND\")\n",
    "print(f\"    Test std:   {y_sale_test.std():.2f} TND\")\n",
    "\n",
    "print(\"\\nðŸ”§ FEATURE ENGINEERING:\")\n",
    "print(f\"  Original features: 7\")\n",
    "print(f\"  Engineered features added: {len(ALL_FEATURES) - 7}\")\n",
    "print(f\"  Total features before encoding: {len(ALL_FEATURES)}\")\n",
    "print(f\"  Total features after encoding: {X_rent_train_prepared.shape[1]}\")\n",
    "\n",
    "print(\"\\nâœ… Ready for model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps_header",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now you're ready to train separate models:\n",
    "\n",
    "1. **For RENT model:**\n",
    "   - Load: `X_rent_train.npy`, `y_rent_train.npy`\n",
    "   - Train models (Linear Regression, Random Forest, XGBoost, etc.)\n",
    "   - Evaluate on `X_rent_test.npy`, `y_rent_test.npy`\n",
    "\n",
    "2. **For SALE model:**\n",
    "   - Load: `X_sale_train.npy`, `y_sale_train.npy`\n",
    "   - Train models (Linear Regression, Random Forest, XGBoost, etc.)\n",
    "   - Evaluate on `X_sale_test.npy`, `y_sale_test.npy`\n",
    "\n",
    "3. **For predictions on new data:**\n",
    "   - Load the appropriate preprocessor (`preprocessor_rent.joblib` or `preprocessor_sale.joblib`)\n",
    "   - Load target encodings\n",
    "   - Apply the same feature engineering\n",
    "   - Transform with the preprocessor\n",
    "   - Predict with your trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
